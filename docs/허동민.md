# 1일차

- 읽어 본 자료 :

[엘라스틱서치(Elasticsearch)에서 관계형 데이터 모델링하기 | 인사이트리포트 | 삼성SDS](https://www.samsungsds.com/kr/insights/elastic_data_modeling.html)

- 느낀 점 : 문서 기반 데이터베이스인 엘라스틱서치는 NoSQL의 일종으로, 삭제 수정과 같은 DML은 지양해야한다. DML이 필요할 때는 RDB를 활용하는 것을 추천. 태생이 검색엔진이므로 **데이터 모델링**이 가장 중요함! **Denormalization 모델링**이 가장 인상 깊었음.
- 다음 찾아볼 자료 : Denormalization 모델링의 방법을 더 조사

# 2일차

- ElasticSearch : 인덱싱한 데이터가 있는 DB라고 생각
- LogStash : RDB에 있는 데이터를 ElasticSearch로 적재시키는 역할
- Kibana : ElasticSearch에 적재된 데이터를 시각적으로 확인할 있는 GUI
- 데이터 확인하는 방법 : [localhost:5601](http://localhost:5601)(ElasticSearch 포트) → http://elasticsearch:9200을 연결(안된다면 https로 시도) → docker-compose에 있는 ./kibana.yml에 적힌 username과 passwor에 맞게 GUI 접속 시도 → 왼쪽 탭의 Management → Dev Tools에 들어가 적절한 명령어 사용
- ex)

```java
GET /board_index/_search
{
  "query": {
    "match_all": {}
  }
}
# board_index : logstash.conf에서 설정한 인덱스명
```

# 3일차

- 엘라스틱 서치는 기본적으로 최대 10000개의 데이터까지만 표출가능하므로 Scroll API나 Search After를 활용하여 초과되는 데이터에 대한 접근이 필요하다.
- 기본적인 GET 검색의 경우 **_score** 필드 내림차순으로 정렬하는데 위 필드의 기준은 검색어와의 유사도를 기준으로 매김
- 필드(RDB의 칼럼)의 타입을 TEXT로 하면 ngram을 통해 부분문자열을 통한 검색을 지원하지만 KEYWORD로 지정할 경우 정확히 일치하는 경우만 검색 지원. wildcard라는 전략을 사용하여 일부 부분문자열을 포함시킬 수는 있음.